{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение рекомендаций с использованием \"чистого\" Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import seaborn as  sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что есть \"схожесть\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы находим похожих пользователей основываясь на их рейтинге?\n",
    "\n",
    "Рассмотрим на базовом примере:\n",
    "\n",
    "1. У нас есть 4 пользователя A, B, C и D, которые оценили 2 рейтинга\n",
    "\n",
    "2. Их оценки выглядят так:\n",
    "    * A = [5.0, 1.0]\n",
    "    * B = [4.0, 4.0]\n",
    "    * C = [3.5, 2.5]\n",
    "    * D = [2.0, 3.0]\n",
    "    \n",
    "3. Они располагаются в пространстве, где ось Y - это фильм 1, а X - это фильм 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переведем это в код\n",
    "a = [5., 1.]\n",
    "b = [4., 4.]\n",
    "c = [3.5, 2.5]\n",
    "d = [2., 3.]\n",
    "\n",
    "labels = [\"A\", \"B\", \"C\", \"D\"]\n",
    "data = np.append([a], [b], axis=0)\n",
    "data = np.append(data, [c], axis=0)\n",
    "data = np.append(data, [d], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# визуализируем данные\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(data[:, 0], data[:, 1], color=\"red\")\n",
    "\n",
    "ax.set_xlabel(\"Фильм 1\")\n",
    "ax.set_ylabel(\"Фильм 2\")\n",
    "\n",
    "\n",
    "for i, word in enumerate(data):\n",
    "    ax.annotate(labels[i], xy=(data[i, 0], data[i, 1]), size=30)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая точка == пользователь. \n",
    "\n",
    "Дистанция между двумя точками - это лучший вариант посчитать похожесть пользователей. На графике уже видно, что есть 2 похожих.\n",
    "\n",
    "Найдем расстояние между точкам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(data[:, 0], data[:, 1], color=\"red\")\n",
    "\n",
    "ax.set_xlabel(\"Фильм 1\")\n",
    "ax.set_ylabel(\"Фильм 2\")\n",
    "\n",
    "for i, word in enumerate(data):\n",
    "    ax.plot(np.array([0,data[i][0]]), np.array([0, data[i][1]]), color=\"red\")\n",
    "    ax.annotate(labels[i], xy=(data[i, 0]+0.001, data[i, 1]), size=20)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### разные варианты сходства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x,y):\n",
    "    from math import pow, sqrt\n",
    "    return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(x,y):\n",
    "    return sum(abs(a-b) for a,b in zip(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nth_root(value, n_root):\n",
    "    from decimal import Decimal\n",
    "    root_value = 1/float(n_root)\n",
    "    return round (Decimal(value) ** Decimal(root_value),3)\n",
    "  \n",
    "def minkowski_distance(x,y,p_value):\n",
    "    from math import pow\n",
    "    return nth_root(sum(pow(abs(a-b),p_value) for a,b in zip(x, y)),p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_rooted(x):\n",
    "    from math import pow, sqrt\n",
    "    return round(sqrt(sum([a*a for a in x])),3)\n",
    "  \n",
    "def cosine_similarity(x,y):\n",
    "    numerator = sum(a*b for a,b in zip(x,y))\n",
    "    denominator = square_rooted(x)*square_rooted(y)\n",
    "    return round(numerator/float(denominator),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance(a,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_distance(a,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = 2 - это считается, как Эвклидово\n",
    "# p = 1 - это считается, как Манхэттен \n",
    "minkowski_distance(a,c, 1), minkowski_distance(a,c, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(a,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### из библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расстояние одной точки А до остальных\n",
    "print(\"A-C:\",spatial.distance.euclidean(a, c))\n",
    "print(\"A-B:\", spatial.distance.euclidean(a, b))\n",
    "print(\"A-D:\", spatial.distance.euclidean(a, d))\n",
    "\n",
    "# действительно считает)\n",
    "print(\"A-А:\", spatial.distance.euclidean(a, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"C-A:\", spatial.distance.cosine(c,a))\n",
    "print(\"C-B:\", spatial.distance.cosine(c,b))\n",
    "print(\"C-D:\", spatial.distance.cosine(c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем расчет по всем точкам\n",
    "\n",
    "dot_list = [a, b, c, d]\n",
    "\n",
    "df = pd.DataFrame(columns = ['U1', 'U2', 'SIM'])\n",
    "\n",
    "n=0\n",
    "\n",
    "for i in dot_list:\n",
    "    for j in dot_list:\n",
    "        \n",
    "        if i != j :\n",
    "            \n",
    "            # используйте выбранный метод и заполните таблицу \n",
    "            result = #\n",
    "            df.loc[n] = #\n",
    "            \n",
    "            n+=1\n",
    "        \n",
    "df.sort_values(by = 'SIM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(data[:, 0], data[:, 1], color=\"red\")\n",
    "\n",
    "ax.set_xlabel(\"Фильм 1\")\n",
    "ax.set_ylabel(\"Фильм 2\")\n",
    "\n",
    "for i, word in enumerate(data):\n",
    "    ax.plot(np.array([0,data[i][0]]), np.array([0, data[i][1]]), color=\"red\")\n",
    "    ax.annotate(labels[i], xy=(data[i, 0]+0.001, data[i, 1]), size=20)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самые далекие точки C - A, а близкие B - D\n",
    "\n",
    "С - пользователь имеет очень похие оценки, возможно, он занижает все оценки по личным причинам.\n",
    "\n",
    "А - пользователь, это самый интересный случай, когда оценивают, только минимально - максимально.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коллаборативная фильтрация (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.metrics.pairwise\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')\n",
    "movies = pd.read_csv('movies.csv')\n",
    "tags = pd.read_csv('tags.csv')\n",
    "\n",
    "#сделаем разбивку\n",
    "train_ratings, test_ratings = sklearn.model_selection.train_test_split(ratings, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "--------------------\n",
    "\n",
    "Для поиска похожих предметов/пользователей мы должны использовать любую метрику схожести. Метрика определяется, как расстояние между двумя векторами.\n",
    "\n",
    "$$\\cos(A,B)=\\frac{\\sum\\limits_{i}^{N}A_iB_i}{\\sqrt{\\sum\\limits_{i}^{N}A_i^2} \\sqrt{\\sum\\limits_{i}^{N}B_i^2}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#сделаем наборы для более удобного поиска\n",
    "movie_users = {}\n",
    "user_movies = {}\n",
    "for index, row in train_ratings.iterrows():\n",
    "    if row['movieId'] not in movie_users:\n",
    "        movie_users[row['movieId']] = {}\n",
    "        \n",
    "    if row['userId'] not in user_movies:\n",
    "        user_movies[row['userId']] = {}\n",
    "        \n",
    "    movie_users[row['movieId']][row['userId']] = row['rating']\n",
    "    user_movies[row['userId']][row['movieId']] = row['rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем расчет по всем пользователям\n",
    "# проверяем разницу на основе cos(A,B)\n",
    "similarities = {}\n",
    "\n",
    "# все фильмы пользователя 1\n",
    "for user1 in user_movies:\n",
    "    if user1 not in similarities:\n",
    "        similarities[user1] = {}\n",
    "    \n",
    "    # все фильмы пользователя 2\n",
    "    for user2 in user_movies:\n",
    "        if user2 in similarities[user1] or user1 == user2:\n",
    "            continue\n",
    "        \n",
    "        user1_ratings = []\n",
    "        user2_ratings = []\n",
    "        \n",
    "        # только те фильме, которые оба пользователя смотрели\n",
    "        # Ваш код здесь\n",
    "                \n",
    "        if len(user1_ratings) > 0:\n",
    "            if user2 not in similarities:\n",
    "                similarities[user2] = {}\n",
    "            \n",
    "            # делаем расчет расстояния\n",
    "            sim = # ваша функция схожести. Используйте numpy и его методы\n",
    "            similarities[user1][user2] = sim\n",
    "            similarities[user2][user1] = sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя похожесть пользователей, сделаем поиск ближайших соседей по формуле\n",
    "\n",
    "$$R_{x,y} = \\frac{\\sum\\limits_{z} Sim_{x,z}R_{z,y}}{\\sum\\limits_{z} Sim_{x,z}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "def knn_predict(k, userId, movieId):\n",
    "    watched_users = movie_users[movieId]\n",
    "    \n",
    "    sim_scores = []\n",
    "    rating_scores = []\n",
    "    \n",
    "    for w in watched_users:\n",
    "        if w in similarities[userId]:\n",
    "            sim_scores.append(similarities[userId][w])\n",
    "            rating_scores.append(watched_users[w])\n",
    "    \n",
    "    #Считаем скоринг и находим ближайших\n",
    "    if len(sim_scores) > 0:\n",
    "        sim_df = pd.DataFrame(data={'sim' : sim_scores, 'rating' : rating_scores})\n",
    "        \n",
    "        # делаем сортировку\n",
    "        sorted_sim_df = sim_df.sort_values(by=['sim'], ascending = False)\n",
    "        # отбор топ - это и есть ближайшие\n",
    "        knearest = sorted_sim_df.head(k)\n",
    "        \n",
    "        numerator = 0\n",
    "        denomenator = 0\n",
    "        for index, row in knearest.iterrows():\n",
    "            numerator += row['sim'] * row['rating']\n",
    "            denomenator += row['sim']\n",
    "        return numerator / denomenator\n",
    "    else: \n",
    "        # можно возвращать любой случайный рейтинг или средний по всем\n",
    "        return 2.5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем расчет\n",
    "\n",
    "# определим кол-во ближайших соседей (набор, чтобы увидеть разницу) \n",
    "Ks= [10, 15, 20, 25]\n",
    "\n",
    "# сделаем подбор для тех, кто есть в тестовой выборке\n",
    "for K in Ks:\n",
    "    predicted_ratings = []\n",
    "    actual_ratings = []\n",
    "\n",
    "    for index, row in test_ratings.iterrows():\n",
    "        if row['movieId'] not in movie_users:\n",
    "            continue\n",
    "\n",
    "        pred = knn_predict(K, row['userId'], row['movieId'])\n",
    "\n",
    "        # сохраним результат\n",
    "        predicted_ratings.append(pred)\n",
    "        actual_ratings.append(row['rating'])\n",
    "    \n",
    "    # метрика (факт / предикт)\n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(predicted_ratings, actual_ratings))\n",
    "    print(\"K - \", K, \" | RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN - но библиотекой Surprise\n",
    "\n",
    "Способ из библиотек, конечно, лучше.\n",
    "\n",
    "Мы можем использовать:\n",
    "- разные метрики для поиска похожих элементов: cosine, msd, pearson, pearson_baseline\n",
    "- использовать user_base / item_based подходы \n",
    "- min_support - минимальное кол-во предметов в наборе для поиска\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "from surprise import KNNWithMeans, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовим заново данные\n",
    "df = pd.read_csv(\"ratings.csv\")\n",
    "movie_titles = pd.read_csv('movies_titles.csv') \n",
    "df['item_id'] = df['movieId']\n",
    "df = df.drop('movieId', axis = 1)\n",
    "\n",
    "movielens = pd.merge(df, movie_titles, on='item_id') \n",
    "\n",
    "movielens.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для работы с библиотекой surprise необходимо подготовить данные\n",
    "\n",
    "# создать объект с мин/макс. оценков\n",
    "reader = # напишем совместно\n",
    "data = # напишем совместно\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем такую же item-based рекомендацию на основе схожести по косиносному расстоянию\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": False,  # расстояние между предметами, не пользователями\n",
    "}\n",
    "algo = KNNWithMeans(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# приедикт для одного пользователя\n",
    "prediction = algo.predict(2718281828, 2)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! Ого !\n",
    "\n",
    "Наш результат 3.64 для фильма 2, но что значит эта надпись: **\"'reason': 'User and/or item is unknown\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# правильный предитк (известный пользователь, не известный предмет для пользователя)\n",
    "algo.predict(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.rmse(algo.test(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Factorization (Рассмотрим на занятии 2)\n",
    "--------\n",
    "\n",
    "Более мощное решение задачи. Коллаборативная фильтрация методом матричного разложения. Применяется для user-item рекомендаций.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Movie1</th>\n",
    "        <th>Movie2</th>\n",
    "        <th>Movie3</th>\n",
    "        <th>Movie4</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>User1</th>\n",
    "        <td>5</td>\n",
    "        <td></td>\n",
    "        <td>1.5</td>\n",
    "        <td>3.5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>User2</th>\n",
    "        <td>1</td>\n",
    "        <td>3.5</td>\n",
    "        <td></td>\n",
    "        <td>4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>User3</th>\n",
    "        <td></td>\n",
    "        <td>2</td>\n",
    "        <td>4</td>\n",
    "        <td>5</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Есть много методов, основной метод [Probabilistic Matrix Factorization](https://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf):\n",
    "$$ R = U^TV$$\n",
    "\n",
    "### $U$ и $V$ ######\n",
    "\n",
    "Как обучать U и V? Методом градиентного спуска и ALS, минимизируя функцию:\n",
    "\n",
    "$$ \n",
    "E = \\frac{1}{2} \\sum\\limits_{i}^{N}\\sum\\limits_{j}^{M}I_{i,j}(R_{i,j} - U_{i}^{T}V_{j})^2 \n",
    "+ \\frac{\\lambda_U}{2} \\sum\\limits_{i}^{N} \\|{U_i}\\|_{Fro}^2\n",
    "+ \\frac{\\lambda_V}{2} \\sum\\limits_{j}^{M} \\|{V_j}\\|_{Fro}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция ошибки\n",
    "def get_error(user_matrix, item_matrix, actual, lu, li):\n",
    "    error = 0\n",
    "    for u in actual:\n",
    "        for i in actual[u]:\n",
    "            pred = np.dot(user_matrix[u], item_matrix[i])\n",
    "            error += (pred - actual[u][i]) ** 2\n",
    "            \n",
    "    error /= 2\n",
    "    \n",
    "    u_norm = 0\n",
    "    for u in user_matrix:\n",
    "        for val in user_matrix[u]:\n",
    "            u_norm += val ** 2\n",
    "    i_norm = 0\n",
    "    for i in item_matrix:\n",
    "        for val in item_matrix[i]:\n",
    "            i_norm += val ** 2\n",
    "            \n",
    "    error += lu * u_norm / 2\n",
    "    error += li * i_norm / 2\n",
    "              \n",
    "    return error\n",
    "    \n",
    "    \n",
    "#производная U\n",
    "def dE_u(user_matrix, item_matrix, actual, lu, u, index):\n",
    "    derivative = 0\n",
    "    for i in actual[u]:\n",
    "        pred = np.dot(user_matrix[u], item_matrix[i])\n",
    "        derivative += (pred - actual[u][i]) * item_matrix[i][index]\n",
    "        \n",
    "    derivative += lu * user_matrix[u][index]\n",
    "    \n",
    "    return derivative \n",
    "\n",
    "#производная V\n",
    "def dE_i(user_matrix, item_matrix, actual, li, i, index):\n",
    "    derivative = 0\n",
    "    watched_users = movie_users[i]\n",
    "    for u in watched_users:\n",
    "        pred = np.dot(user_matrix[u], item_matrix[i])\n",
    "        derivative += (pred - actual[u][i]) * user_matrix[u][index]\n",
    "        \n",
    "    derivative += li * item_matrix[i][index]\n",
    "    \n",
    "    return derivative\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ALS\n",
    "def learn(user_matrix, item_matrix, actual, lu, li, learning_rate):\n",
    "    counter = 0\n",
    "    while counter < 10:\n",
    "        error = get_error(user_matrix, item_matrix, actual, lu, li)\n",
    "        print(\"Counter:\", counter, \"Error:\", error) #Error should trend downwards over time\n",
    "        \n",
    "        #Используем V константой, обновляем U с градиентом\n",
    "        if counter % 2 == 0:\n",
    "            user_derivatives = {}      \n",
    "            for u in user_matrix:\n",
    "                user_derivatives[u] = []\n",
    "            \n",
    "                for index in range(len(user_matrix[u])):\n",
    "                    user_derivatives[u].append(dE_u(user_matrix, item_matrix, actual, lu, u, index))\n",
    "                    \n",
    "            for u in user_matrix:\n",
    "                for index in range(len(user_matrix[u])):\n",
    "                    user_matrix[u][index] -= learning_rate * user_derivatives[u][index]\n",
    "\n",
    "        #Используем U константой, обновляем V с градиентом\n",
    "        else:\n",
    "            item_derivatives = {}\n",
    "            for i in item_matrix:\n",
    "                item_derivatives[i] = []\n",
    "                for index in range(len(item_matrix[i])):\n",
    "                    item_derivatives[i].append(dE_i(user_matrix, item_matrix, actual, li, i, index))\n",
    "                    \n",
    "            for i in item_matrix:\n",
    "                for index in range(len(item_matrix[i])):\n",
    "                    item_matrix[i][index] -= learning_rate * item_derivatives[i][index]\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "    return (user_matrix, item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_matrix = {}\n",
    "item_matrix = {}\n",
    "learning_rate = 0.0001\n",
    "lu = 0.0001\n",
    "li = 0.0001\n",
    "K = 5\n",
    "\n",
    "for u in user_movies:\n",
    "    user_matrix[u] = random.sample(range(1, 100), K)\n",
    "    for index in range(K):\n",
    "        user_matrix[u][index] /= float(100)\n",
    "    \n",
    "for i in movie_users:\n",
    "    item_matrix[i] = random.sample(range(1, 100), K)\n",
    "    for index in range(K):\n",
    "        item_matrix[i][index] /= float(100)\n",
    "    \n",
    "learned_users, learned_items = learn(user_matrix, item_matrix, user_movies, lu, li, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = []\n",
    "actuals = []\n",
    "not_count = 0\n",
    "for index, row in test_ratings.iterrows():\n",
    "    if row['movieId'] not in movie_users:\n",
    "        continue\n",
    "        \n",
    "    pred = np.dot(learned_users[row['userId']], learned_items[row['movieId']])\n",
    "    predicted_ratings.append(pred)\n",
    "    actuals.append(row['rating'])\n",
    "\n",
    "rmse = math.sqrt(sklearn.metrics.mean_squared_error(predicted_ratings, actuals))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MF - но библиотекой Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(movielens[['userId', 'item_id', 'rating']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем алгоритм SVD, т.к. он один из самых популярных, его автор Simon Funk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
